<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>OpenAI Realtime WebSocket Audio Test</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      max-width: 800px;
      margin: 0 auto;
      padding: 20px;
    }
    button {
      padding: 10px 20px;
      font-size: 16px;
      margin: 5px;
      background: #007bff;
      color: white;
      border: none;
      border-radius: 5px;
      cursor: pointer;
    }
    button:hover {
      background: #0056b3;
    }
    button:disabled {
      background: #6c757d;
      cursor: not-allowed;
    }
    .record-btn {
      background: #dc3545;
    }
    .record-btn:hover {
      background: #c82333;
    }
    .recording {
      background: #28a745 !important;
      animation: pulse 1s infinite;
    }
    @keyframes pulse {
      0% { opacity: 1; }
      50% { opacity: 0.7; }
      100% { opacity: 1; }
    }
    #log {
      background: #f8f9fa;
      border: 1px solid #dee2e6;
      border-radius: 5px;
      padding: 10px;
      height: 300px;
      overflow-y: auto;
      font-family: monospace;
      white-space: pre-wrap;
    }
    audio {
      width: 100%;
      margin: 20px 0;
    }
    .controls {
      margin-bottom: 20px;
    }
  </style>
</head>
<body>
  <h1>Realtime WebSocket Audio Test</h1>
  
  <div class="controls">
    <button id="connectBtn">Connect</button>
    <button id="recordBtn" class="record-btn" disabled>ðŸŽ¤ Start Recording</button>
    <button id="sendTextBtn" disabled>Send Text Message</button>
    <input type="file" id="audioFileInput" accept="audio/*" multiple style="margin: 10px 0;">
    <button id="uploadAudioBtn" disabled>Upload Audio Files</button>
  </div>
  
  <pre id="log"></pre>
  <audio id="player" controls></audio>

  <script>
    let ws;
    let audioChunks = [];
    let isConnected = false;
    let mediaRecorder;
    let recordedChunks = [];
    let isRecording = false;

    // Audio processing functions
    function floatTo16BitPCM(float32Array) {
      const buffer = new ArrayBuffer(float32Array.length * 2);
      const view = new DataView(buffer);
      let offset = 0;
      for (let i = 0; i < float32Array.length; i++, offset += 2) {
        let s = Math.max(-1, Math.min(1, float32Array[i]));
        view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);
      }
      return buffer;
    }

    function base64EncodeAudio(float32Array) {
      const arrayBuffer = floatTo16BitPCM(float32Array);
      let binary = '';
      let bytes = new Uint8Array(arrayBuffer);
      const chunkSize = 0x8000; // 32KB chunk size
      for (let i = 0; i < bytes.length; i += chunkSize) {
        let chunk = bytes.subarray(i, i + chunkSize);
        binary += String.fromCharCode.apply(null, chunk);
      }
      return btoa(binary);
    }

    // Decode audio file to Float32Array
    async function decodeAudioFile(audioBuffer) {
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const decodedData = await audioContext.decodeAudioData(audioBuffer);
      return decodedData.getChannelData(0); // Get first channel
    }

    async function connect() {
      const logEl = document.getElementById("log");
      const connectBtn = document.getElementById("connectBtn");
      const recordBtn = document.getElementById("recordBtn");
      const sendTextBtn = document.getElementById("sendTextBtn");
      const uploadAudioBtn = document.getElementById("uploadAudioBtn");
      const audioEl = document.getElementById("player");
      
      function log(msg) { 
        const timestamp = new Date().toLocaleTimeString();
        logEl.textContent += `[${timestamp}] ${msg}\n`; 
        logEl.scrollTop = logEl.scrollHeight;
      }

      // Replace with your actual API key
      const API_KEY = "";
      connectBtn.disabled = true;
      connectBtn.textContent = "Connecting...";
      audioChunks = [];

      try {
        ws = new WebSocket(
          "wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview",
          [
            "realtime",
            "openai-insecure-api-key." + API_KEY,
            "openai-beta.realtime-v1"
          ]
        );

        ws.onopen = () => {
          log(" Connected to OpenAI Realtime API");
          isConnected = true;
          connectBtn.textContent = "Connected";
          recordBtn.disabled = false;
          sendTextBtn.disabled = false;
          uploadAudioBtn.disabled = false;
          
          // Configure the session
          ws.send(JSON.stringify({
            type: "session.update",
            session: {
              type: "realtime",
              modalities: ["text", "audio"],
              instructions: "You are a helpful assistant. Respond naturally to whatever the user says or asks.Answer in English only",
              voice: "alloy",
              output_audio_format: "pcm16",
              turn_detection: {
                type: "server_vad",
                threshold: 0.5,
                prefix_padding_ms: 300,
                silence_duration_ms: 500
              }
            }
          }));
        };

        ws.onmessage = (event) => {
          const data = JSON.parse(event.data);
          log(` Received: ${data.type}`);

          if (data.type === "response.audio.delta") {
            log(` Audio chunk received (${data.delta.length} chars base64)`);
            
            // Decode base64 to binary
            const binaryString = atob(data.delta);
            const bytes = new Uint8Array(binaryString.length);
            for (let i = 0; i < binaryString.length; i++) {
              bytes[i] = binaryString.charCodeAt(i);
            }
            
            audioChunks.push(bytes);
          }

          if (data.type === "response.audio.done") {
            log("Audio response completed, creating playable audio");
            createAudioFromChunks();
          }

          if (data.type === "response.done") {
            log("ðŸŽ‰ Complete response finished");
          }

          if (data.type === "error") {
            log(`âŒ Error: ${JSON.stringify(data.error)}`);
          }
        };

        ws.onerror = (err) => {
          log(`âŒ WebSocket Error: ${err.message || 'Unknown error'}`);
          resetConnection();
        };

        ws.onclose = (event) => {
          log(`ðŸ”’ Connection closed (code: ${event.code})`);
          resetConnection();
        };

      } catch (error) {
        log(`âŒ Connection failed: ${error.message}`);
        resetConnection();
      }
    }

    function resetConnection() {
      isConnected = false;
      document.getElementById("connectBtn").disabled = false;
      document.getElementById("connectBtn").textContent = "Connect";
      document.getElementById("recordBtn").disabled = true;
      document.getElementById("sendTextBtn").disabled = true;
      document.getElementById("uploadAudioBtn").disabled = true;
    }

    // Recording functionality
    async function toggleRecording() {
      const recordBtn = document.getElementById("recordBtn");
      const logEl = document.getElementById("log");
      
      function log(msg) { 
        const timestamp = new Date().toLocaleTimeString();
        logEl.textContent += `[${timestamp}] ${msg}\n`; 
        logEl.scrollTop = logEl.scrollHeight;
      }

      if (!isRecording) {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          mediaRecorder = new MediaRecorder(stream);
          recordedChunks = [];

          mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
              recordedChunks.push(event.data);
            }
          };

          mediaRecorder.onstop = async () => {
            const audioBlob = new Blob(recordedChunks, { type: 'audio/wav' });
            await processRecordedAudio(audioBlob);
            
            // Stop all tracks to release microphone
            stream.getTracks().forEach(track => track.stop());
          };

          mediaRecorder.start();
          isRecording = true;
          recordBtn.textContent = "ðŸ›‘ Stop Recording";
          recordBtn.classList.add("recording");
          log("ðŸŽ¤ Recording started...");

        } catch (error) {
          log(`âŒ Error starting recording: ${error.message}`);
        }
      } else {
        mediaRecorder.stop();
        isRecording = false;
        recordBtn.textContent = "ðŸŽ¤ Start Recording";
        recordBtn.classList.remove("recording");
        log("â¹ï¸ Recording stopped, processing...");
      }
    }

    // Process recorded audio and send to API
    async function processRecordedAudio(audioBlob) {
      const logEl = document.getElementById("log");
      
      function log(msg) { 
        const timestamp = new Date().toLocaleTimeString();
        logEl.textContent += `[${timestamp}] ${msg}\n`; 
        logEl.scrollTop = logEl.scrollHeight;
      }

      try {
        const arrayBuffer = await audioBlob.arrayBuffer();
        const channelData = await decodeAudioFile(arrayBuffer);
        const base64Chunk = base64EncodeAudio(channelData);
        
        log("ðŸ“¤ Sending recorded audio to API...");
        audioChunks = []; // Clear previous response
        
        // Send audio to API
        ws.send(JSON.stringify({
          type: 'input_audio_buffer.append',
          audio: base64Chunk
        }));
        
        ws.send(JSON.stringify({type: 'input_audio_buffer.commit'}));
        ws.send(JSON.stringify({type: 'response.create'}));
        
      } catch (error) {
        log(`âŒ Error processing audio: ${error.message}`);
      }
    }

    // Upload audio files functionality
    async function uploadAudioFiles() {
      const fileInput = document.getElementById("audioFileInput");
      const files = fileInput.files;
      const logEl = document.getElementById("log");
      
      function log(msg) { 
        const timestamp = new Date().toLocaleTimeString();
        logEl.textContent += `[${timestamp}] ${msg}\n`; 
        logEl.scrollTop = logEl.scrollHeight;
      }

      if (files.length === 0) {
        log("âš ï¸ Please select audio files first");
        return;
      }

      try {
        log(`ðŸ“ Processing ${files.length} audio file(s)...`);
        audioChunks = []; // Clear previous response

        // Process each file
        for (const file of files) {
          log(`ðŸŽµ Processing: ${file.name}`);
          const arrayBuffer = await file.arrayBuffer();
          const channelData = await decodeAudioFile(arrayBuffer);
          const base64Chunk = base64EncodeAudio(channelData);
          
          ws.send(JSON.stringify({
            type: 'input_audio_buffer.append',
            audio: base64Chunk
          }));
        }

        // Commit and create response
        ws.send(JSON.stringify({type: 'input_audio_buffer.commit'}));
        ws.send(JSON.stringify({type: 'response.create'}));
        
        log("ðŸ“¤ All audio files sent to API");

      } catch (error) {
        log(`âŒ Error uploading files: ${error.message}`);
      }
    }

    // Send text message
    function sendTextMessage() {
      const message = prompt("Enter your message:");
      if (!message) return;

      const logEl = document.getElementById("log");
      function log(msg) { 
        const timestamp = new Date().toLocaleTimeString();
        logEl.textContent += `[${timestamp}] ${msg}\n`; 
        logEl.scrollTop = logEl.scrollHeight;
      }

      log(`ðŸ’¬ Sending text: "${message}"`);
      audioChunks = []; // Clear previous response

      ws.send(JSON.stringify({
        type: "conversation.item.create",
        item: {
          type: "message",
          role: "user",
          content: [{
            type: "input_text",
            text: message
          }]
        }
      }));

      ws.send(JSON.stringify({
        type: "response.create",
        response: {
          modalities: ["text", "audio"]
        }
      }));
    }

    function createAudioFromChunks() {
      if (audioChunks.length === 0) {
        return;
      }

      const logEl = document.getElementById("log");

      try {
        // Calculate total length
        const totalLength = audioChunks.reduce((sum, chunk) => sum + chunk.length, 0);
        log(`Combining ${audioChunks.length} chunks, total ${totalLength} bytes`);

        // Combine all chunks
        const combinedAudio = new Uint8Array(totalLength);
        let offset = 0;
        for (const chunk of audioChunks) {
          combinedAudio.set(chunk, offset);
          offset += chunk.length;
        }

        // Convert PCM16 to WAV format
        const wavData = createWavFile(combinedAudio, 24000, 1); // 24kHz, mono
        const blob = new Blob([wavData], { type: 'audio/wav' });
        const audioUrl = URL.createObjectURL(blob);

        const audioEl = document.getElementById("player");
        audioEl.src = audioUrl;
        audioEl.load();
        
        
        // Auto-play the audio
        audioEl.play().catch(e => {
          log(`Auto-play failed: ${e.message}. Click play button manually.`);
        });

      } catch (error) {
        log(`Error creating audio: ${error.message}`);
      }
    }

    function createWavFile(audioData, sampleRate, numChannels) {
      const length = audioData.length;
      const buffer = new ArrayBuffer(44 + length * 2);
      const view = new DataView(buffer);

      // WAV header
      const writeString = (offset, string) => {
        for (let i = 0; i < string.length; i++) {
          view.setUint8(offset + i, string.charCodeAt(i));
        }
      };

      writeString(0, 'RIFF');
      view.setUint32(4, 36 + length * 2, true);
      writeString(8, 'WAVE');
      writeString(12, 'fmt ');
      view.setUint32(16, 16, true);
      view.setUint16(20, 1, true);
      view.setUint16(22, numChannels, true);
      view.setUint32(24, sampleRate, true);
      view.setUint32(28, sampleRate * 2, true);
      view.setUint16(32, 2, true);
      view.setUint16(34, 16, true);
      writeString(36, 'data');
      view.setUint32(40, length * 2, true);

      // Convert PCM data
      const offset = 44;
      for (let i = 0; i < length; i += 2) {
        const sample = (audioData[i + 1] << 8) | audioData[i];
        view.setInt16(offset + i, sample, true);
      }

      return buffer;
    }

    // Event listeners
    document.getElementById("connectBtn").onclick = connect;
    document.getElementById("recordBtn").onclick = toggleRecording;
    document.getElementById("sendTextBtn").onclick = sendTextMessage;
    document.getElementById("uploadAudioBtn").onclick = uploadAudioFiles;
  </script>
</body>
</html>
